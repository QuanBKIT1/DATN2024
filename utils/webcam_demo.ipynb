{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import lib (C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pprint\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pre_processing import preprocess\n",
    "from post_processing import postprocess\n",
    "from inference import inference_batch_imgs\n",
    "import configs\n",
    "from utils import import_class, build_session, prepare_data, draw_skeleton\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file (C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file for mapping (video_id, label, gloss)\n",
    "json_path = configs.WLASL_JSON_PATH\n",
    "\n",
    "wlasl_class_list_path = configs.WLASL_CLASS_LIST_PATH\n",
    "\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    wlasl2000_json = json.load(f)  # Mapping video id to label\n",
    "\n",
    "\n",
    "with open(wlasl_class_list_path, mode='r') as f:\n",
    "    lines = f.readlines()\n",
    "    label_to_gloss = dict()\n",
    "    for line in lines:\n",
    "        data = line.split('\\t')\n",
    "        label = int(data[0])\n",
    "        gloss = data[1].rstrip()\n",
    "        label_to_gloss[label] = gloss       # Mapping label to gloss\n",
    "\n",
    "# # Read video data path\n",
    "# input_dirs = [\n",
    "#     r\"D:\\DATN\\project\\data\\raw_data\\rgb\\WLASL2000\\train\\\\\",\n",
    "#     r\"D:\\DATN\\project\\data\\raw_data\\rgb\\WLASL2000\\val\\\\\",\n",
    "#     r\"D:\\DATN\\project\\data\\raw_data\\rgb\\WLASL2000\\test\\\\\",\n",
    "# ]\n",
    "# paths = []\n",
    "# for dir_path in input_dirs:\n",
    "#     path1 = []\n",
    "#     for root, _, fnames in os.walk(dir_path):\n",
    "#         for fname in fnames:\n",
    "#             path0 = os.path.join(root, fname)\n",
    "#             path1.append(path0)\n",
    "#     paths.append(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pose estimator model and GCN model (A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../onnx_model/rtmw-l+.onnx\n",
      "../checkpoints/stgcnpp-31-rtmw_onehot_top1=54.66.yaml\n",
      "../checkpoints/stgcnpp-31-rtmw_onehot_top1=54.66.pt\n"
     ]
    }
   ],
   "source": [
    "# Config area\n",
    "\n",
    "index_GCN = 2\n",
    "index_PE = 0        # index_PE = 1 if index_GCN = 1\n",
    "num_keypoint = 31   # 27 if index_GCN = 0,1 and 31 if index_GCN = 2,3\n",
    "\n",
    "# -------------------------------- POSE ESTIMATOR CONFIG -------------------------------- #\n",
    "# onnx_file = r\"D:\\DATN\\project\\data_prepare\\onnx_model\\rtmw-dw-x-l_simcc-cocktail14_270e-384x288_20231122\\end2end.onnx\"\n",
    "# onnx_file = r\"D:\\DATN\\project\\data_prepare\\onnx_model\\rtmpose-l_simcc-ucoco_dw-ucoco_270e-256x192-4d6dfc62_20230728\\20230831\\rtmpose_onnx\\rtmpose-l_simcc-ucoco_dw-ucoco_270e-256x192-4d6dfc62_20230728\\end2end.onnx\"\n",
    "\n",
    "pe_onnx_paths = configs.PE_ONNX_PATHS\n",
    "pe_onnx_path = pe_onnx_paths[index_PE]\n",
    "device = \"cpu\"\n",
    "\n",
    "# -------------------------------- GCN MODEL CONFIG -------------------------------- #\n",
    "\n",
    "# model_config_path = r'D:\\DATN\\project\\Pose-based-WLASL\\checkpoints\\stgcnpp-27-rtmw_onehot_top1=53.09.yaml'\n",
    "\n",
    "model_config_paths = configs.MODEL_CONFIG_PATHS\n",
    "weight_paths = configs.WEIGHT_PATHS\n",
    "\n",
    "weight_path = weight_paths[index_GCN]\n",
    "model_config_path = model_config_paths[index_GCN]\n",
    "\n",
    "print(pe_onnx_path)\n",
    "print(model_config_path)\n",
    "print(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download HPE ONNX file\n",
    "# import urllib.request\n",
    "# import shutil\n",
    "# import zipfile\n",
    "\n",
    "# if not os.path.exists(r'..\\onnx_model\\rtmpose-l.onnx') and not os.path.exists(r'..\\onnx_model\\rtmw-l+.onnx'):\n",
    "#     os.makedirs('../onnx_model', exist_ok=True)\n",
    "#     rtml_url = 'https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/onnx_sdk/rtmpose-l_simcc-ucoco_dw-ucoco_270e-256x192-4d6dfc62_20230728.zip'\n",
    "#     rtmw_url = 'https://download.openmmlab.com/mmpose/v1/projects/rtmw/onnx_sdk/rtmw-dw-x-l_simcc-cocktail14_270e-384x288_20231122.zip'\n",
    "\n",
    "#     rtml_name = r'..\\onnx_model\\rtmpose-l.zip'\n",
    "#     rtmw_name = r'..\\onnx_model\\rtmw-l+.zip'\n",
    "#     # Download\n",
    "#     print(\"Download RTMPose-l\")\n",
    "#     urllib.request.urlretrieve(rtml_url, rtml_name)\n",
    "#     print(\"Download RTMW\")\n",
    "#     urllib.request.urlretrieve(rtmw_url, rtmw_name)\n",
    "\n",
    "#     # Extract zip file\n",
    "#     with zipfile.ZipFile(rtml_name, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(r'..\\onnx_model\\rtmpose-l')\n",
    "#     with zipfile.ZipFile(rtmw_name, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(r'..\\onnx_model\\rtmw-l+')\n",
    "\n",
    "#     # Copy onnx file\n",
    "    \n",
    "\n",
    "# # Cleaning\n",
    "# rtmpose_folder_path = '..\\onnx_model\\rtmpose-l'\n",
    "# rtmw_folder_path = '..\\onnx_model\\rtmw-l+'\n",
    "# os.remove(rtml_name)\n",
    "# os.remove(rtmw_name)\n",
    "# shutil.rmtree(rtmpose_folder_path)\n",
    "# shutil.rmtree(rtmw_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model from config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pose estimator from ONNX file: ../onnx_model/rtmw-l+.onnx\n",
      "Input size of pose estimator (288,384)\n",
      "Load GCN from config: ../checkpoints/stgcnpp-31-rtmw_onehot_top1=54.66.yaml\n",
      "Load GCN weight from: ../checkpoints/stgcnpp-31-rtmw_onehot_top1=54.66.pt\n",
      "{'Experiment_name': 'st-gcn-pp', 'base_lr': 0.1, 'batch_size': 64, 'eval_interval': 1, 'feeder': 'feeder.feeder.Feeder', 'model': 'model.stgcn_pp.stgcn_pp.Model', 'model_args': {'gcn_adaptive': 'init', 'gcn_with_res': True, 'graph': 'graph.graph.Graph', 'graph_args': {'layout': 'keypoint-31', 'mode': 'spatial'}, 'in_channels': 3, 'num_class': 2000, 'tcn_type': 'mstcn'}, 'model_saved_dir': '/kaggle/working/output/save_models', 'nesterov': True, 'num_epoch': 100, 'num_worker': 2, 'optimizer': 'SGD', 'phase': 'train', 'print_log': True, 'save_interval': 20, 'show_topk': [1], 'start_epoch': 0, 't_max': 100, 'test_batch_size': 64, 'test_feeder_args': {'data_path': '/kaggle/input/skeleton-31-rtm-l-384-288/skeleton-31-rtm-l-384-288/test_data_joint.npy', 'label_path': '/kaggle/input/skeleton-31-rtm-l-384-288/skeleton-31-rtm-l-384-288/test_label.pkl', 'normalization': True, 'random_mirror': False}, 'train_feeder_args': {'data_path': '/kaggle/input/skeleton-31-rtm-l-384-288/skeleton-31-rtm-l-384-288/train_data_joint.npy', 'is_vector': False, 'label_path': '/kaggle/input/skeleton-31-rtm-l-384-288/skeleton-31-rtm-l-384-288/train_label.pkl', 'max_xy': 256, 'normalization': True, 'random_choose': True, 'random_mirror': True, 'random_mirror_p': 0.5, 'random_move': True, 'random_shift': True, 'window_size': 80}, 'val_feeder_args': {'data_path': '/kaggle/input/skeleton-31-rtm-l-384-288/skeleton-31-rtm-l-384-288/val_data_joint.npy', 'label_path': '/kaggle/input/skeleton-31-rtm-l-384-288/skeleton-31-rtm-l-384-288/val_label.pkl', 'normalization': True, 'random_mirror': False}, 'weight_decay': 0.0005, 'weights': 0, 'work_dir': '/kaggle/working/output/work_dir'}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------- LOAD POSE ESTIMATOR MODEL -------------------------------- #\n",
    "\n",
    "# Build session with ONNXRuntime\n",
    "sess = build_session(pe_onnx_path, device)\n",
    "print(f\"Load pose estimator from ONNX file: {pe_onnx_path}\")\n",
    "\n",
    "h, w = sess.get_inputs()[0].shape[2:]\n",
    "model_input_size = (w, h)\n",
    "print(f\"Input size of pose estimator ({w},{h})\")\n",
    "\n",
    "\n",
    "# -------------------------------- LOAD GCN MODEL -------------------------------- #\n",
    "\n",
    "with open(model_config_path) as f:\n",
    "    arg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "arg = argparse.Namespace(**arg)\n",
    "\n",
    "Model = import_class(arg.model)\n",
    "model = Model(**arg.model_args)\n",
    "print(f\"Load GCN from config: {model_config_path}\")\n",
    "\n",
    "weights = torch.load(weight_path, map_location='cpu')\n",
    "new_weights = {}\n",
    "for key, value in weights.items():\n",
    "    new_weights[key[7:]] = value\n",
    "\n",
    "model.load_state_dict(new_weights)\n",
    "model.eval()\n",
    "print(f\"Load GCN weight from: {weight_path}\")\n",
    "print(vars(arg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline prediction from video path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sign Language Recognition from video path\n",
    "\n",
    "def predict_offline(video_path, num_keypoint=27):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    gloss, results, total_frames, pose_time, model_time \n",
    "\n",
    "    gloss: Text for sign\n",
    "    results: Output from pose estimator with shape (T,W,H)\n",
    "    total_frames : length frame of video \n",
    "    pose_time: time for pose estimation\n",
    "    model_time: time for model inference\n",
    "\n",
    "    \"\"\"\n",
    "    print(video_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    stack_frame = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        resized_img, center, scale = preprocess(frame, model_input_size)\n",
    "        stack_frame.append(resized_img)\n",
    "\n",
    "    # Time for pose estimation\n",
    "    stack_frame = np.array(stack_frame, dtype=np.float32)\n",
    "    total_frames = stack_frame.shape[0]\n",
    "    print(f\"{stack_frame.shape[0]} frames\")\n",
    "    # Stack frame shape:  (34, 256, 192, 3)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # inference\n",
    "    outputs = inference_batch_imgs(sess, stack_frame)\n",
    "    # postprocessing\n",
    "    keypoints, scores = postprocess(outputs, model_input_size, center, scale)\n",
    "    pose_time = time.time() - start_time\n",
    "\n",
    "    results = np.concatenate((keypoints, scores[:, :, None]), axis=2)\n",
    "\n",
    "    # keypoints.shape = (56, 133, 2)\n",
    "    # scores.shape = (56,133, )\n",
    "\n",
    "    # Data-prepare for GCN model\n",
    "    data = prepare_data(results, num_keypoint)\n",
    "\n",
    "    # results.shape: (3, 150, 27, 1)\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        data = torch.Tensor(data)\n",
    "        predictions = model(data)\n",
    "    model_time = time.time() - start_time\n",
    "\n",
    "    label = torch.argmax(predictions)\n",
    "    gloss = label_to_gloss[int(label)]\n",
    "\n",
    "    print(\"pose time:\", pose_time)\n",
    "    print(\"model inference  time: \", model_time)\n",
    "\n",
    "    return gloss, results, predictions, total_frames, pose_time, model_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize result\n",
    "\n",
    "def visualize_results(video_path, results, predictions, predict_label, true_label='x',  output_size=(512, 512), display_label=False, save_video=False, replay_fps=15):\n",
    "    # Pipeline: Replay video, draw results to video, print predict label\n",
    "    video_id = os.path.basename(video_path).split('.')[0]\n",
    "\n",
    "    # ----------------------------- Visualize prediction ----------------------------- #\n",
    "    os.makedirs(configs.SAVE_VISUALIZE_DIR, exist_ok=True)\n",
    "\n",
    "    output_save_fig = r\"{}\\score_{}.png\".format(\n",
    "        configs.SAVE_VISUALIZE_DIR,   video_id)\n",
    "\n",
    "    softmax_layer = nn.Softmax(dim=0)\n",
    "    probality_each_class = softmax_layer(torch.tensor(predictions)[0]).numpy()\n",
    "    sort_probality_index = np.argsort(probality_each_class)[-5:]\n",
    "\n",
    "    # Create scores\n",
    "\n",
    "    top_label = sort_probality_index[::-1]\n",
    "    scores = probality_each_class[top_label]\n",
    "    glosses = [label_to_gloss[index] for index in top_label]\n",
    "    print(glosses, scores)\n",
    "    plt.bar(glosses, scores, label='xyz')\n",
    "\n",
    "    # Add labels and title to the chart\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f\"Predict video with true label = \\'{true_label}\\'\")\n",
    "    plt.savefig(output_save_fig)\n",
    "    plt.show()\n",
    "\n",
    "    # ----------------------------- Display true label ----------------------------- #\n",
    "    if display_label:\n",
    "        # Create image display predict text\n",
    "        predict_img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "        text = predict_label\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1\n",
    "        color = (255, 255, 255)  # White color in BGR\n",
    "        thickness = 2\n",
    "\n",
    "        text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
    "        # Center horizontally\n",
    "        text_x = (predict_img.shape[1] - text_size[0]) // 2\n",
    "        # Center vertically\n",
    "        text_y = (predict_img.shape[0] + text_size[1]) // 2\n",
    "        cv2.putText(predict_img, text, (text_x, text_y),\n",
    "                    font, font_scale, color, thickness)\n",
    "        cv2.imshow(\"Predict label\", predict_img)\n",
    "\n",
    "        if true_label != 'x':\n",
    "            # Create image display true text\n",
    "            true_img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "            text = true_label\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 1\n",
    "            color = (255, 255, 255)  # White color in BGR\n",
    "            thickness = 2\n",
    "\n",
    "            text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
    "            text_x = (true_img.shape[1] - text_size[0]\n",
    "                      ) // 2  # Center horizontally\n",
    "            text_y = (true_img.shape[0] + text_size[1]\n",
    "                      ) // 2  # Center vertically\n",
    "            cv2.putText(true_img, text, (text_x, text_y),\n",
    "                        font, font_scale, color, thickness)\n",
    "            cv2.imshow(\"True label\", true_img)\n",
    "\n",
    "    # ----------------------------- Replay video with skeleton ----------------------------- #\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    i = 0\n",
    "\n",
    "    if save_video:\n",
    "        frames = []\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        fps = replay_fps\n",
    "        frame_width = frame_height = 256\n",
    "\n",
    "        output_video_filename = r\"{}\\skeleton_{}.mp4\".format(\n",
    "            configs.SAVE_VISUALIZE_DIR, video_id)\n",
    "        output_video1_filename = r\"{}\\rgb_{}.mp4\".format(\n",
    "            configs.SAVE_VISUALIZE_DIR, video_id)\n",
    "\n",
    "        selected_index = []\n",
    "        for i, result in enumerate(results):\n",
    "            if np.all(result[:, :2] <= 300) and np.all(result[:, :2] >= -50):\n",
    "                selected_index.append(i)\n",
    "                frame = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "                # Extract frame with not in (x,y)\n",
    "\n",
    "                frame = draw_skeleton(frame, result, num_keypoint)\n",
    "                frames.append(frame)\n",
    "\n",
    "        video_frames = []\n",
    "        i = 0\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if i in selected_index:\n",
    "                video_frames.append(frame)\n",
    "            i += 1\n",
    "        print(len(video_frames))\n",
    "\n",
    "        out = cv2.VideoWriter(output_video_filename, fourcc,\n",
    "                              fps, (frame_width, frame_height))\n",
    "        for frame in frames:\n",
    "            out.write(frame)\n",
    "\n",
    "        out1 = cv2.VideoWriter(output_video1_filename, fourcc,\n",
    "                               fps, (frame_width, frame_height))\n",
    "\n",
    "        for frame in video_frames:\n",
    "            out1.write(frame)\n",
    "\n",
    "        out.release()\n",
    "        out1.release()\n",
    "\n",
    "        print(\"Save video to \", output_video_filename)\n",
    "        print(\"Save video to \", output_video1_filename)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        i = 0\n",
    "\n",
    "        while (True):\n",
    "            if i == len(frames):\n",
    "                i = 0\n",
    "                continue\n",
    "\n",
    "            frame = frames[i]\n",
    "            video_frame = video_frames[i]\n",
    "\n",
    "            frame = cv2.resize(frame, output_size)\n",
    "            video_frame = cv2.resize(video_frame, output_size)\n",
    "            time.sleep(1 / replay_fps)\n",
    "            cv2.imshow(\"RGB Video\", video_frame)\n",
    "            cv2.imshow(\"Skeleton Video\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    else:\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                i = 0\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                continue\n",
    "            frame = draw_skeleton(frame, results[i], num_keypoint)\n",
    "            frame = cv2.resize(frame, output_size)\n",
    "            time.sleep(1 / replay_fps)\n",
    "            cv2.imshow(\"Video\", frame)\n",
    "\n",
    "            i += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/video_demo\\57667.mp4\n",
      "66 frames\n",
      "pose time: 15.256780624389648\n",
      "model inference  time:  0.9833486080169678\n",
      "thank you     thank you\n",
      "['thank you', 'thankful', 'good', 'sweet', 'wolf'] [9.9364966e-01 1.4982306e-03 7.7855081e-04 5.2938395e-04 4.5979861e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Quan\\AppData\\Local\\Temp\\ipykernel_8124\\1356431405.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probality_each_class = softmax_layer(torch.tensor(predictions)[0]).numpy()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "Save video to  ../visualize_tmp\\skeleton_57667.mp4\n",
      "Save video to  ../visualize_tmp\\rgb_57667.mp4\n"
     ]
    }
   ],
   "source": [
    "# 27175, 45721, 57667\n",
    "video_path = os.path.join(configs.VIDEO_DEMO_PATH, '57667.mp4')\n",
    "\n",
    "gloss, results, predictions, total_frames, pose_time, model_time = predict_offline(\n",
    "    video_path, num_keypoint)\n",
    "video_id = os.path.basename(video_path).split('.')[0]\n",
    "\n",
    "true_label = wlasl2000_json[video_id]['action'][0]\n",
    "true_gloss = label_to_gloss[true_label]\n",
    "print(gloss, '   ', true_gloss)\n",
    "visualize_results(video_path, results, predictions,\n",
    "                  gloss, true_gloss, save_video=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict video from WLASL2000 folder\n",
    "# video_paths = paths[2][:20]\n",
    "# memory = []\n",
    "# predict_true = 0\n",
    "# for video_path in video_paths:\n",
    "#     gloss, results, predictions, total_frames, pose_time, model_time = predict_offline(\n",
    "#         video_path, num_keypoint)\n",
    "#     memory.append((total_frames, pose_time, model_time))\n",
    "#     video_id = os.path.basename(video_path).split('.')[0]\n",
    "#     true_label = wlasl2000_json[video_id]['action'][0]\n",
    "#     true_gloss = label_to_gloss[true_label]\n",
    "#     print(gloss, '   ', true_gloss)\n",
    "#     if gloss == true_gloss:\n",
    "#         predict_true += 1\n",
    "\n",
    "# # Time counting\n",
    "# memory = np.array(memory)\n",
    "# sum_up_memory = np.sum(memory, axis=0)\n",
    "# print(\"pose time per frame: \", sum_up_memory[1]/sum_up_memory[0])\n",
    "# print(\"model time per a inference: \", sum_up_memory[2]/sum_up_memory[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
